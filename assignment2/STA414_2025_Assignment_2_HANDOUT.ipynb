{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taliafabs/sta414/blob/main/STA414_2025_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "248_qtulv8jx"
      },
      "source": [
        "# Probabilistic ML: Assignment 2\n",
        "- **Deadline**: Feb 16, 23:59 ET\n",
        "- **Submission**: You need to submit your solutions through Crowdmark, including all your derivations, plots, and your code. You can produce the files however you like (e.g. $\\LaTeX$, Microsoft Word, etc), as long as it is readable. Points will be deducted if we have a hard time reading your solutions or understanding the structure of your code.\n",
        "- **Collaboration policy**: After attempting the problems on an individual basis, you may discuss and work together on the assignment with up to two classmates. However, **you must write your own code and write up your own solutions individually and explicitly name any collaborators** at the top of the homework.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y82CCb3pwLJT"
      },
      "source": [
        "# Q1 - Image Denoising"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCI65iZNRDuP"
      },
      "source": [
        "In this problem, we will implement the max-product Loopy **belief propagation** (Loopy-BP) method for denoising binary images which you have seen in tutorial 4.\n",
        "We will consider images as matrices of size $\\sqrt{n} \\times \\sqrt{n}$. Each element of the matrix can be either $1$ or $-1$, with $1$ representing white pixels and $-1$ representing black pixels. This is different from the $0/1$ representation commonly used for other CV tasks. This notation will be more convenient when multiplying with pixel values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AbNhBClT0R0"
      },
      "source": [
        "### Data preparation\n",
        "Below we provide you with code for loading and preparing the image data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6cfep0ywRbF"
      },
      "source": [
        "First, we load a black and white image and convert it into a binary matrix of 1 and -1. So that white pixels have value 1 and black pixels have value -1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e0odMis14XP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "19000c7f-cb3a-418c-ef65-a003ddb3b475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.11/dist-packages (3.2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b73d8789950>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install wget\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import PIL.Image as Image\n",
        "from os.path import exists\n",
        "from wget import download\n",
        "from tqdm import tqdm\n",
        "\n",
        "filename, url = \"trc1l3gqu9651.png\", \"https://i.redd.it/trc1l3gqu9651.png\"\n",
        "\n",
        "def load_img():\n",
        "    if not exists(filename):\n",
        "        download(url)\n",
        "\n",
        "    with open(filename, 'rb') as fp:\n",
        "        img2 = Image.open(fp).convert('L')\n",
        "        img2 = img2.resize((96, 96), Image.LANCZOS)\n",
        "        img2 = np.array(img2)\n",
        "    return (img2 > 120) * 2.0 - 1\n",
        "\n",
        "img_true = load_img()\n",
        "plt.imshow(img_true, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdn-UR3f1_Lk"
      },
      "source": [
        "To introduce noise into the image, for each pixel, swap its value between 1 and -1 with rate 0.2.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EBQQa1h2m8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "3e147446-c3ba-4ae8-fb86-742f87ce7659"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b73d8819450>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def gen_noisyimg(img, noise=.05):\n",
        "    swap = np.random.binomial(1, noise, size=img.shape)\n",
        "    return img * (1 - 2 * swap)\n",
        "\n",
        "noise = 0.2\n",
        "img_noisy = gen_noisyimg(img_true, noise)\n",
        "plt.imshow(img_noisy, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea_81p9xY5Ux"
      },
      "source": [
        "### The Loopy BP algorithm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfJKaB1mqYY-"
      },
      "source": [
        "Recall from lecture and tutorial, the Loopy-BP algorithm iteratively updates the messages of each node through a sum-product or max-product operation. The sum-product operation computes the joint inbound message through multiplication, and then marginalizes the factors through summation. This is in contrast to the max-product BP, which computes the maximum a-posteriori (MAP) value for each variable through taking the maximum over variables. In this question, we will implement the **max-product** BP to obtain the MAP estimate\n",
        "\n",
        "Initialization:\n",
        "\n",
        "For discrete node $x_j$ with $2$ possible states, $m_{i \\rightarrow j}$ can be written as a $2$ dimensional real vector $\\mathrm{m}_{i,j}$ with $m_{i \\rightarrow j}(x_j) =  \\mathrm{m}_{i,j}[index(x_j)]$. We initialize them uniformly to $m_{i \\rightarrow j}(x_j) = 1/2$.\n",
        "\n",
        "(Aside: for continuous cases, $m_{i \\rightarrow j}(x_j)$ is a real valued function of $x_j$. We only need to deal with the discrete case here.)\n",
        "\n",
        "For a number of iterations:\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;For node $x_j$ in $\\{x_s\\}_{s=1}^n$:  \n",
        "1. Compute the product of inbound messages from neighbours of $x_j$:\n",
        "$$\\prod_{k \\in N(j) \\not = i} m_{k \\rightarrow j}(x_j)$$\n",
        "\n",
        "2. Compute potentials $\\psi_j(x_j) = \\exp (\\beta x_j y_j)$ and $\\psi_{ij}(x_i,x_j) = \\exp(J x_i x_j)$. This expression specifically holds when $x \\in \\{-1,+1\\}$.\n",
        "\n",
        "3. Maximize over $x_j = \\{-1, +1\\}$ to get $m_{j \\rightarrow i}(x_i)$:\n",
        "$$\n",
        "m_{j \\rightarrow i}(x_i) = \\max_{x_j}\\psi_j(x_j)\\psi_{ij}(x_i, x_j)\\prod_{k \\in N(j) \\not = i} m_{k \\rightarrow j}(x_j)\n",
        "$$\n",
        "4. Normalize messages for stability $m_{j \\rightarrow i}(x_i) =m_{j \\rightarrow i}(x_i)/\\sum_{x_i}m_{j \\rightarrow i}(x_i)$.\n",
        "\n",
        "Compute beliefs after message passing is done.\n",
        "$$\n",
        "b(x_i) \\propto \\psi_i(x_i) \\prod_{j \\in N(i)} m_{j \\rightarrow i}(x_i).\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnK7tMk7o0a7"
      },
      "source": [
        "You'll be tasked to perform steps 1-3 in the iterations and computing the beliefs. We will provide you with helper functions for initialization, finding neighbours, and normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecxN71ic4HHM"
      },
      "source": [
        "### Initialization\n",
        "Initialize the message between neighbor pixels uniformly as $m_{j→i}(x_i) = 1/k$. Since each pixel can only be 1 or -1, message has two values $m_{j→i}(1)$ and $m_{j→i}(-1)$. We also initialize hyperparameters $J$ and $\\beta$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdvYSWEP6KBn"
      },
      "outputs": [],
      "source": [
        "y = img_noisy.reshape([img_true.size, ])\n",
        "num_nodes = len(y)\n",
        "init_message = np.zeros([2, num_nodes, num_nodes]) + .5\n",
        "J = 1.0\n",
        "beta = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH_-BYgQ6U_X"
      },
      "source": [
        "Find the neighboring pixels around a given pixel, which will be used for BP updates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU-WR4d_6b8Q"
      },
      "outputs": [],
      "source": [
        "def get_neighbors_of(node):\n",
        "    \"\"\"\n",
        "    arguments:\n",
        "     int node:  in [0,num_nodes) index of node to query\n",
        "    globals:\n",
        "     int num_nodes: number of nodes\n",
        "    return: set(int) indices of neighbors of queried node\n",
        "    \"\"\"\n",
        "    neighbors = []\n",
        "    m = int(np.sqrt(num_nodes))\n",
        "    if (node + 1) % m != 0:\n",
        "        neighbors += [node + 1]\n",
        "    if node % m != 0:\n",
        "        neighbors += [node - 1]\n",
        "    if node + m < num_nodes:\n",
        "        neighbors += [node + m]\n",
        "    if node - m >= 0:\n",
        "        neighbors += [node - m]\n",
        "\n",
        "    return set(neighbors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csfddvHbrJqN"
      },
      "source": [
        "## Q1.1 Implement message passing in BP [20 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhnSTVvsrZco"
      },
      "source": [
        "Implement the function `get_message()` that computes the message passed from node j to node i: $$\n",
        "m_{j \\rightarrow i}(x_i) = \\max_{x_j}\\psi_j(x_j)\\psi_{ij}(x_i, x_j)\\prod_{k \\in N(j) \\not = i} m_{k \\rightarrow j}(x_j)\n",
        "$$\n",
        "`get_message()` will be used by (provided below) `step_bp()` to perform one iteration of loopy-BP: it first normalizes the returned message from `get_message()`, and then updates the message with momentum `1.0 - step`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-8YaDcsAule"
      },
      "outputs": [],
      "source": [
        "def get_message(node_from, node_to, messages):\n",
        "    \"\"\"\n",
        "    arguments:\n",
        "     int node_from: in [0,num_nodes) index of source node\n",
        "     int node_from: in [0,num_nodes) index of target node\n",
        "     float array messages: (2, num_nodes, num_nodes), messages[:,j,i] is message\n",
        "                           from node j to node i\n",
        "    reads globals:\n",
        "     float array y: (num_nodes,) observed pixel values\n",
        "     float J: clique coupling strength constant\n",
        "     float beta: observation to true pixel coupling strength constant\n",
        "    return: array(float) of shape (2,) un-normalized message from node_from to\n",
        "    node_to\n",
        "    \"\"\"\n",
        "    #TODO: implement your function here\n",
        "    # start by getting neighbors of node_from\n",
        "    neighbors = get_neighbors_of(node_from)\n",
        "    m_new = np.zeros([2, ])\n",
        "    pass\n",
        "\n",
        "\n",
        "def step_bp(step, messages):\n",
        "    \"\"\"\n",
        "    arguments:\n",
        "     float step: step size to update messages\n",
        "    return\n",
        "     float array messages: (2, num_nodes, num_nodes), messages[:,j,i] is message\n",
        "                           from node j to node i\n",
        "    \"\"\"\n",
        "    for node_from in range(num_nodes):\n",
        "        for node_to in get_neighbors_of(node_from):\n",
        "            m_new = get_message(node_from, node_to, messages)\n",
        "            # normalize\n",
        "            m_new = m_new / np.sum(m_new)\n",
        "\n",
        "            messages[:, node_from, node_to] = step * m_new + (1. - step) * \\\n",
        "                messages[:, node_from, node_to]\n",
        "    return messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT0uYbgPBkmc"
      },
      "source": [
        "Then, run loopy BP update for 10 iterations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgyCPXzZB3Cr"
      },
      "outputs": [],
      "source": [
        "num_iter = 10\n",
        "step = 0.5\n",
        "for it in range(num_iter):\n",
        "    init_message = step_bp(step, init_message)\n",
        "    print(it + 1,'/',num_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjZiEu3Lx9yq"
      },
      "source": [
        "## Q1.2 Computing belief from messages [10 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXScm4ptCJVt"
      },
      "source": [
        "Now, calculate the unnormalized belief for each pixel\n",
        "$$ \\tilde{b}(x_i) = \\psi_i(x_i) ∏_{j \\in N(i)}m_{j→i}(x_i),$$\n",
        "and normalize the belief across all pixels\n",
        "$$ b(x_i) = \\frac{\\tilde{b}(x_i)}{∑_{x_j}\\tilde{b}(x_j)}.$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpxG9ht5DVEw"
      },
      "outputs": [],
      "source": [
        "def update_beliefs(messages):\n",
        "    \"\"\"\n",
        "    arguments:\n",
        "    float array messages: (2, num_nodes, num_nodes), messages[:,j,i] is message\n",
        "                           from node j to node i\n",
        "    reads globals:\n",
        "     float beta: observation to true pixel coupling strength constant\n",
        "     float array y: (num_nodes,) observed pixel values\n",
        "    returns:\n",
        "     float array beliefs: (2, num_nodes), beliefs[:,i] is the belief of node i\n",
        "    \"\"\"\n",
        "    beliefs = np.zeros([2, num_nodes])\n",
        "    for node in range(num_nodes):\n",
        "        #TODO: implement belief calculation here\n",
        "\n",
        "    return beliefs\n",
        "\n",
        "# call update_beliefs() once\n",
        "beliefs = update_beliefs(init_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQaLL3IHEFQJ"
      },
      "source": [
        "Finally, to get the denoised image, we use 0.5 as the threshold and consider pixel with belief less than threshold as black while others as white, which is the same as choosing the pixel with maximum probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUy2g0RrEauz"
      },
      "outputs": [],
      "source": [
        "pred = 2. * ((beliefs[0, :] > .5) + .0) - 1.\n",
        "img_out = pred.reshape(img_true.shape)\n",
        "\n",
        "plt.imshow(np.hstack([img_true, img_noisy, img_out]), cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkARhGaI_DMS"
      },
      "source": [
        "## Q1.3 Momentum in belief propagation [10 points]\n",
        "In the sample code provided above, we performed message update with a momentum parameter `step`. In this question, you will experimentally investigate how momentum affects the characteristics of convergence.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVUUENILADnN"
      },
      "source": [
        "### Q1.3.a [5 points]\n",
        "Complete the function `test_trajectory` below to obtain predicted image after each step of message passing. Return predicted images as list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuxFaVTT_C5Q"
      },
      "outputs": [],
      "source": [
        "def test_trajectory(step_size, max_step=10):\n",
        "    \"\"\"\n",
        "    step_size: step_size to update messages in each iteration\n",
        "    max_step: number of steps\n",
        "    \"\"\"\n",
        "    # re-initialize each time\n",
        "    messages = np.zeros([2, num_nodes, num_nodes]) + .5\n",
        "    images = []\n",
        "\n",
        "    # solution:\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twJ96AkWGhyn"
      },
      "source": [
        "### Q1.3.b [5 points]\n",
        "Use test trajectory to create image serieses for `step size` 0.1, 0.3, and 1.0, each with 10 steps. Display these images with `plot_series' provided below.\n",
        "\n",
        "In the textbox below: 1. Comment on what happens when a large step size is used for too many iterations. 2. How would you adjust other hyperparameters to counteract this effect?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LE9EOa_wGoDy"
      },
      "outputs": [],
      "source": [
        "def plot_series(images):\n",
        "  n = len(images)\n",
        "  fig, ax = plt.subplots(1, n)\n",
        "  for i in range(n):\n",
        "    ax[i].imshow(images[i], cmap='gray')\n",
        "    ax[i].set_axis_off()\n",
        "  fig.set_figwidth(10)\n",
        "  fig.show()\n",
        "\n",
        "#Solution:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g-syMv4NqNO"
      },
      "source": [
        "### Response to 1.3.b (Enter your response below):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70Gwz5oeURqA"
      },
      "source": [
        "## Q1.4 Noise level and the hyperparameter $J$ [10 points]\n",
        "In this question, we will study how the level of noise in the image influences our choice in the hyperparameter $J$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3xc-hWyYsbR"
      },
      "source": [
        "### Q1.4.a [5 points]\n",
        "First, generate and display images with noise of $0.05$, $0.3$.\n",
        "In the text box below, comment on what would happen if noise was set to $0.5$ and $1.0$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx7nVjO3ZaLB"
      },
      "outputs": [],
      "source": [
        "# Solution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RFharDeZQEv"
      },
      "source": [
        "### Response to 1.4.a (enter your response below):\n",
        "Solution: at 0.5, the image would be purely noise. at 1.0, the image would be inverted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7AWsNqGaQYt"
      },
      "source": [
        "### Q1.4.b [5 points]\n",
        "Now, perform image denoising on images with noise levels $0.05$ and $0.3$ using $J=0.1$, $J=0.5$, $J=1.0$, and $J=5.0$. Set step size to 0.8 and max_step to 5. Plot the denoised images (if reusing `test_trajectory`, you should plot 8 image serieses).\n",
        "In text box below, comment on what you observe and provide a brief explanation on why this might occur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcEDdqlhFsX9"
      },
      "outputs": [],
      "source": [
        "# Solution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKf1FdlOcA7w"
      },
      "source": [
        "### Response to 1.4.b (enter your response below):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pznCr4ORzMxz"
      },
      "source": [
        "# Question 2: Markov chain Monte Carlo in the TrueSkill model\n",
        "\n",
        "The goal of this question is to get you familiar with the basics of\n",
        "Bayesian inference in medium-sized models with continuous latent variables, and the basics of Langevin and Hamiltonian Monte Carlo.\n",
        "\n",
        "## Background\n",
        "\n",
        "We'll implement a variant of the [TrueSkill](http://papers.nips.cc/paper/3079-trueskilltm-a-bayesian-skill-rating-system.pdf) model, a player ranking system for competitive games originally developed for Halo 2.\n",
        "It is a generalization of the Elo rating system in Chess.\n",
        "\n",
        "This assignment is based on [this one](https://mlg.eng.cam.ac.uk/teaching/4f13/2324/) developed by Carl Rasmussen at Cambridge for his course on probabilistic machine learning.\n",
        "\n",
        "## Model definition\n",
        "We'll consider a slightly simplified version of the original trueskill model.\n",
        "We assume that each player has a true, but unknown skill $z_i \\in \\mathbb{R}$.\n",
        "We use $N$ to denote the number of players.\n",
        "\n",
        "### The prior:\n",
        "The prior over each player's skill is a standard normal distribution, and all player's skills are *a priori* independent.\n",
        "\n",
        "### The likelihood:\n",
        "For each observed game, the probability that player $i$ beats player $j$, given the player's skills $z_A$ and $z_B$, is:\n",
        "$$p(A \\,\\, \\text{beat} \\,\\, B | z_A, z_B) = \\sigma(z_A - z_B)$$\n",
        "where\n",
        "$$\\sigma(y) = \\frac{1}{1 + \\exp(-y)}$$\n",
        "We chose this function simply because it's close to zero or one when the player's skills are very different, and equals one-half when the player skills are the same.  This likelihood function is the only thing that gives meaning to the latent skill variables $z_1 \\dots z_N$.\n",
        "\n",
        "There can be more than one game played between a pair of players. The outcome of each game is independent given the players' skills.\n",
        "We use $M$ to denote the number of games.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXAnW7vS1kBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4efa60-e56e-4f87-f1a2-800203bd3a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=1468075f35fb8f9eb0a8d03073e0eb593dfd4c3b3fa6dbc98a8f158cf0124573\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import wget\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import scipy.io\n",
        "import scipy.stats\n",
        "import torch\n",
        "import random\n",
        "from torch.distributions.normal import Normal\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwWGMLQnyOzq"
      },
      "source": [
        "## Q 2.1 Implementing the TrueSkill Model [10 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSyMyS3u4BmU"
      },
      "source": [
        "###\tQ 2.1.a [4 points]\n",
        "Implement a function $\\texttt{log_joint_prior}$ that computes the log of the prior, jointly evaluated over all player's skills.\n",
        "\n",
        "  Specifically, given a $K \\times N$ array where each row is a setting of the skills for all $N$ players, it returns a $K \\times 1$ array, where each row contains a scalar giving the log-prior for that set of skills."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwzYPxUm4Nrp"
      },
      "outputs": [],
      "source": [
        "def log_joint_prior(zs_array):\n",
        "  # TODO\n",
        "  log_prior = np.zeros(zs_array.shape[0])\n",
        "  for i in range(zs_array.shape[0]):\n",
        "    log_prior[i] = np.sum(norm.logpdf(zs_array[i]))\n",
        "  return log_prior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeLyjDNG4N9k"
      },
      "source": [
        "### Q 2.1.b [6 points]\n",
        "\n",
        "Implement two functions $\\texttt{logp_a_beats_b}$ and $\\texttt{logp_b_beats_a}$.\n",
        "\n",
        "Given a pair of skills $z_a$ and $z_b$, $\\texttt{logp_a_beats_b}$ evaluates the log-likelihood that player with skill $z_a$ beat player with skill $z_b$ under the model detailed above, and $\\texttt{logp_b_beats_a}$ is vice versa.\n",
        "\n",
        "To ensure numerical stability, use the function $torch.logaddexp$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QguZaNGP4OMs"
      },
      "outputs": [],
      "source": [
        "def logp_a_beats_b(z_a, z_b):\n",
        "  # Hint: Use torch.logaddexp\n",
        "  # TODO\n",
        "  pass\n",
        "\n",
        "def logp_b_beats_a(z_a, z_b):\n",
        "  # Hint: Use torch.logaddexp\n",
        "  # TODO\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM30M_GN4O6V"
      },
      "source": [
        "## Q 2.2 Examining the posterior for only two players and toy data [10 points]\n",
        "To get a feel for this model, we'll first consider the case where we only have 2 players, $A$ and $B$.\n",
        "We'll examine how the prior and likelihood interact when conditioning on different sets of games.\n",
        "\n",
        "Provided in the starter code is a function $\\texttt{plot_isocontours}$ which evaluates a provided function on a grid of $z_A$ and $z_B$'s and plots the isocontours of that function.\n",
        "There is also a function $\\texttt{plot_2d_fun}$.\n",
        "We have included an example for how you can use these functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lGCtaEe7uAP"
      },
      "outputs": [],
      "source": [
        "# Plotting helper functions\n",
        "def plot_isocontours(ax, func, steps=100):\n",
        "    x = torch.linspace(-4, 4, steps=steps)\n",
        "    y = torch.linspace(-4, 4, steps=steps)\n",
        "    X, Y = torch.meshgrid(x, y, indexing=\"ij\")\n",
        "    Z = func(X, Y)\n",
        "    cs = plt.contour(X, Y, Z )\n",
        "    plt.clabel(cs, inline=1, fontsize=10)\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xticks([])\n",
        "\n",
        "def plot_2d_fun(f, x_axis_label=\"\", y_axis_label=\"\", scatter_pts=None):\n",
        "    # This is the function your code should call.\n",
        "    # f() should take two arguments.\n",
        "    fig = plt.figure(figsize=(8,8), facecolor='white')\n",
        "    ax = fig.add_subplot(111, frameon=False)\n",
        "    ax.set_xlabel(x_axis_label)\n",
        "    ax.set_ylabel(y_axis_label)\n",
        "    plot_isocontours(ax, f)\n",
        "    if scatter_pts is not None:\n",
        "      plt.scatter(scatter_pts[:,0], scatter_pts[:, 1])\n",
        "    plt.plot([4, -4], [4, -4], 'b--')   # Line of equal skill\n",
        "    plt.show(block=True)\n",
        "    plt.draw()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIfAUAs77YFA"
      },
      "source": [
        "### Q 2.2.a [2 point]\n",
        "For two players $A$ and $B$, plot the isocontours of the joint prior over their skills.  Also plot the line of equal skill, $z_A = z_B$. Use the helper function `plot_2d_fun` above to plot.\n",
        "\n",
        "According to the prior, what's the chance that player A is better than player B?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MifKIY8E4O_-"
      },
      "outputs": [],
      "source": [
        "def log_prior_over_2_players(z1, z2):\n",
        "  # TODO\n",
        "  pass\n",
        "\n",
        "def prior_over_2_players(z1, z2):\n",
        "  return torch.exp(log_prior_over_2_players(z1, z2))\n",
        "\n",
        "plot_2d_fun(prior_over_2_players, \"Player A Skill\", \"Player B Skill\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DifTVtfb4PFw"
      },
      "source": [
        "### Q 2.2.b [3 points]\n",
        "\n",
        "Plot isocountours of the joint posterior over $z_A$ and $z_B$ given that player A\n",
        "beat player B in one match.  Since the contours don't depend on the normalization\n",
        "constant, you can simply plot the isocontours of the log of joint distribution of\n",
        "$p(z_A, z_B | \\text{A beat B})$. Also plot the line of equal skill, $z_A = z_B$.\n",
        "\n",
        "To think about: According to this posterior, which player is likely to have higher skill?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Pc0ywn-4PLj"
      },
      "outputs": [],
      "source": [
        "def log_posterior_A_beat_B(z1, z2):\n",
        "  # TODO: Combine the prior for two players with the likelihood for A beat B.\n",
        "  # You might want to use the log_prior_over_2_players function from above.\n",
        "  pass\n",
        "\n",
        "def posterior_A_beat_B(z1, z2):\n",
        "  return torch.exp(log_posterior_A_beat_B(z1, z2))\n",
        "\n",
        "plot_2d_fun(posterior_A_beat_B, \"Player A Skill\", \"Player B Skill\")\n",
        "# Note that the posterior probabilities shown are unnormalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVyuktMfhnnR"
      },
      "source": [
        "### Q 2.2.c [2 point]\n",
        "\n",
        "Plot isocountours of the joint posterior over $z_A$ and $z_B$ given that\n",
        "5 matches were played, and player A beat player B in all matches.\n",
        "Also plot the line of equal skill, $z_A = z_B$.\n",
        "\n",
        "To think about: According to this posterior, is it plausible that player B is more skilled than player A?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jRN4IQihx06"
      },
      "outputs": [],
      "source": [
        "def log_posterior_A_beat_B_5_times(z1, z2):\n",
        "  # TODO: Combine the prior for two players with the likelihood for A beat B.\n",
        "  # You might want to use your log_prior_over_2_players function.\n",
        "  pass\n",
        "\n",
        "def posterior_A_beat_B_5_times(z1, z2):\n",
        "  return torch.exp(log_posterior_A_beat_B_5_times(z1, z2))\n",
        "\n",
        "plot_2d_fun(posterior_A_beat_B_5_times, \"Player A Skill\", \"Player B Skill\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNS1NGR7hycx"
      },
      "source": [
        "### Q 2.2.d [3 point]\n",
        "\n",
        "Plot isocontours of the joint posterior over $z_A$ and $z_B$ given that\n",
        "10 matches were played, and each player beat the other 5 times.\n",
        "Also plot the line of equal skill, $z_A = z_B$.\n",
        "\n",
        "To think about: According to this posterior, is it likely that one player is much better than another?  Is it plausible that both players are better than average?  Worse than average?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuNG2H9-PA6x"
      },
      "outputs": [],
      "source": [
        "def log_posterior_beat_each_other_5_times(z1, z2):\n",
        "  # TODO: Combine the prior for two players with the likelihood for A beat B.\n",
        "  # You might want to use your log_prior_over_2_players function from above.\n",
        "  pass\n",
        "\n",
        "def posterior_beat_each_other_5_times(z1, z2):\n",
        "  return torch.exp(log_posterior_beat_each_other_5_times(z1, z2))\n",
        "\n",
        "plot_2d_fun(posterior_beat_each_other_5_times, \"Player A Skill\", \"Player B Skill\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK7FpPFX4PQH"
      },
      "source": [
        "## Q 2.3 Hamiltonian and Langevin Monte Carlo on Two Players and Toy Data [8 points]\n",
        "\n",
        "One nice thing about a Bayesian approach is that it separates the model specification from the approximate inference strategy.\n",
        "The original Trueskill paper from 2007 used message passing.\n",
        "Carl Rasmussen's assignment uses Gibbs sampling.\n",
        "\n",
        "In this question, we will approximate posterior distributions with gradient-based Hamiltonian and Langevin Monte Carlo.\n",
        "\n",
        "In the next assignment, we'll use gradient-based stochastic variational inference, which wasn't invented until around 2014.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "NQyPfklJ3KPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahZH12p-4PU1"
      },
      "outputs": [],
      "source": [
        "# Hamiltonian Monte Carlo\n",
        "from tqdm import trange, tqdm_notebook  # Progress meters\n",
        "\n",
        "def leapfrog(params_t0, momentum_t0, stepsize, logprob_grad_fun):\n",
        "  # Performs a reversible update of parameters and momentum\n",
        "  # See https://en.wikipedia.org/wiki/Leapfrog_integration\n",
        "  momentum_thalf = momentum_t0    + 0.5 * stepsize * logprob_grad_fun(params_t0)\n",
        "  params_t1 =      params_t0      +       stepsize * momentum_thalf\n",
        "  momentum_t1 =    momentum_thalf + 0.5 * stepsize * logprob_grad_fun(params_t1)\n",
        "  return params_t1, momentum_t1\n",
        "\n",
        "\n",
        "def iterate_leapfrogs(theta, v, stepsize, num_leapfrog_steps, grad_fun):\n",
        "  for i in range(0, num_leapfrog_steps):\n",
        "    theta, v = leapfrog(theta, v, stepsize, grad_fun)\n",
        "  return theta, v\n",
        "\n",
        "def metropolis_hastings(state1, state2, log_posterior):\n",
        "  # Compares the log_posterior at two values of parameters,\n",
        "  # and accepts the new values proportional to the ratio of the posterior\n",
        "  # probabilities.\n",
        "  accept_prob = torch.exp(log_posterior(state2) - log_posterior(state1))\n",
        "  if random.random() < accept_prob:\n",
        "    return state2  # Accept\n",
        "  else:\n",
        "    return state1  # Reject\n",
        "\n",
        "def draw_samples_hmc(num_params, stepsize, num_leapfrog_steps, n_samples, log_posterior):\n",
        "  theta = torch.zeros(num_params)\n",
        "\n",
        "  def log_joint_density_over_params_and_momentum(state):\n",
        "    params, momentum = state\n",
        "    m = Normal(0., 1.)\n",
        "    return m.log_prob(momentum).sum(axis=-1) + log_posterior(params)\n",
        "\n",
        "  def grad_fun(zs):\n",
        "    zs = zs.detach().clone()\n",
        "    zs.requires_grad_(True)\n",
        "    y = log_posterior(zs)\n",
        "    y.backward()\n",
        "    return zs.grad\n",
        "\n",
        "\n",
        "\n",
        "  sampleslist = []\n",
        "  for i in trange(0, n_samples):\n",
        "    sampleslist.append(theta)\n",
        "\n",
        "    momentum = torch.normal(0, 1, size = np.shape(theta))\n",
        "\n",
        "    theta_new, momentum_new = iterate_leapfrogs(theta, momentum, stepsize, num_leapfrog_steps, grad_fun)\n",
        "\n",
        "    theta, momentum = metropolis_hastings((theta, momentum), (theta_new, momentum_new), log_joint_density_over_params_and_momentum)\n",
        "  return torch.stack((sampleslist))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJveURu04PZH"
      },
      "source": [
        "Using samples generated by HMC, we can approximate the joint posterior where we observe player A winning 1 game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0OEf6ungefm"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "num_players = 2\n",
        "num_leapfrog_steps = 20\n",
        "n_samples = 2500\n",
        "stepsize = 0.01\n",
        "\n",
        "def log_posterior_a(zs):\n",
        "  z1, z2 = zs[0], zs[1]\n",
        "  return log_posterior_A_beat_B(z1, z2)\n",
        "\n",
        "samples_a = draw_samples_hmc(num_players, stepsize, num_leapfrog_steps, n_samples, log_posterior_a)\n",
        "plot_2d_fun(posterior_A_beat_B, \"Player A Skill\", \"Player B Skill\", samples_a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6OMmOzwge6r"
      },
      "source": [
        "### Q 2.3.a [2 point]\n",
        "\n",
        "Using samples generated by HMC, approximate the joint posterior where we observe player A winning 5 games against player B.  Hint:  You can re-use the code from when you plotted the isocontours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrgIHAACgfJO"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "num_players = 2\n",
        "num_leapfrog_steps = 20\n",
        "n_samples = 2500\n",
        "stepsize = 0.01\n",
        "\n",
        "\n",
        "def log_posterior_b(zs):\n",
        "  # TODO\n",
        "  pass\n",
        "\n",
        "\n",
        "# TODO Run HMC and plot the posterior contour and the samples\n",
        "# samples_b = ...\n",
        "# plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWY2rL6rgfYh"
      },
      "source": [
        "### Q 2.3.b [2 point]\n",
        "\n",
        "Using samples generated by HMC, approximate the joint posterior where we observe player A winning 5 games and player B winning 5 games."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMUs_8RagfhW"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "num_players = 2\n",
        "num_leapfrog_steps = 20\n",
        "n_samples = 2500\n",
        "stepsize = 0.01\n",
        "\n",
        "def log_posterior_c(zs):\n",
        "  # TODO\n",
        "  pass\n",
        "\n",
        "# TODO Run HMC and plot the posterior contour and the samples\n",
        "# samples_c = ...\n",
        "# plot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q 2.3.c [2 points]"
      ],
      "metadata": {
        "id": "O-jEWpb6HOym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now implement the simpler Langevin Monte Carlo algorithm with the Metropolis-Hastings filter. Recall that to sample from a posterior distribution $p(z|D)$ with LMC, starting from some intialization $z_0$, we iteratively compute the proposal\n",
        "$$z'_{t+1} = z_t + \\eta \\nabla \\log p(z|D) + \\sqrt{2 * \\eta}W,$$\n",
        "where $W \\sim N(0,I)$. Then, we accept $z'_{t+1}$ according to the Metrapolis-Hastings Algorithm, i.e. we define\n",
        "$$A = \\frac{p(z'_{t+1}|D)\\exp\\big(-\\Vert z_t - z'_{t+1} - \\eta * \\nabla \\log p(z'_{t+1}|D)\\Vert^2\\big)}{p(z_t|D)\\exp\\big(-\\Vert z'_{t+1} - z_t - \\eta * \\nabla \\log p(z_t|D)\\Vert^2\\big)}.$$\n",
        "We then generate $u \\sim \\mathrm{Unif}(0,1)$, and accept the proposal iff $u \\leq A$, in other words\n",
        "$$z_{t+1} = \\begin{cases}z'_{t+1} & \\text{if}\\, u \\leq A\\\\\n",
        "z_t & \\text{if}\\, u > A\\end{cases}.$$\n",
        "\n",
        "Complete the following implementation of LMC with the Metropolis-Hastings filter."
      ],
      "metadata": {
        "id": "59RPkz52HYyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_samples_lmc(num_params, stepsize, n_samples, log_posterior):\n",
        "  zs = torch.zeros(num_params)\n",
        "\n",
        "  def grad_log_posterior(zs):\n",
        "    zs = zs.detach().clone()\n",
        "    zs.requires_grad_(True)\n",
        "    y = log_posterior(zs)\n",
        "    y.backward()\n",
        "    return zs.grad\n",
        "\n",
        "  sampleslist = []\n",
        "  for i in trange(0, n_samples):\n",
        "    sampleslist.append(zs)\n",
        "\n",
        "    # TODO: Perform LMC with Metrapolis Hastings step to get new zs\n",
        "    # Hint: You can reuse the metraplis_hastings method from before\n",
        "    # Hint: You can use grad_log_posterior\n",
        "\n",
        "\n",
        "  return torch.stack((sampleslist))"
      ],
      "metadata": {
        "id": "0qlJ-wsBHaHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the provided code to generate samples via LMC for approximating the joint posterior where we observe player A winning 5 games and player B winning 5 games."
      ],
      "metadata": {
        "id": "5pWss74RskL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_players = 2\n",
        "n_samples = 2500\n",
        "stepsize = 0.01\n",
        "key=42\n",
        "\n",
        "samples_b_lmc = draw_samples_lmc(num_players, stepsize, n_samples, log_posterior_b)\n",
        "\n",
        "ax = plot_2d_fun(posterior_A_beat_B_5_times, \"Player A Skill\", \"Player B Skill\", samples_b_lmc)"
      ],
      "metadata": {
        "id": "Bfr4yrkneFIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.3.d [2 points]\n",
        "In the answer box below, provide one general advantage and one general disadvantage of LMC in comaprison with HMC."
      ],
      "metadata": {
        "id": "uYPL-7tlxlXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(enter your response here):"
      ],
      "metadata": {
        "id": "hYV5GKV5xtkc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMWbazNsgfqa"
      },
      "source": [
        "## Q 2.4 Approximate inference conditioned on real data [26 points]\n",
        "\n",
        "The dataset contains data on 2500 games amongst 33 Premier League teams:\n",
        " - names is a 33 by 1 matrix, whose $i$’th entry is the name of player $i$.\n",
        " - games is a 2500 by 2 matrix of game outcomes, one row per game.\n",
        "\n",
        "The first column contains the indices of the team who won.\n",
        "The second column contains the indices of the team who lost. Note that what we refer to as team here is the same as a player in the previous parts; we assume each team has a skill following the TrueSkill model.\n",
        "\n",
        "It is based on the following kaggle dataset: https://www.kaggle.com/datasets/evangower/premier-league-matches-19922022\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!curl -L -o premier-league-matches-19922022.zip\\\n",
        "  https://www.kaggle.com/api/v1/datasets/download/evangower/premier-league-matches-19922022\n",
        "!unzip premier-league-matches-19922022.zip"
      ],
      "metadata": {
        "id": "6Zp6arRZzfVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def load_games():\n",
        "    dataset = pd.read_csv(\"premier-league-matches.csv\")\n",
        "    mini_ds = dataset[dataset['FTR'] != 'D'][-2500:]\n",
        "    all_teams = pd.concat((mini_ds['Home'], mini_ds['Away'])).unique()\n",
        "    encoder = LabelEncoder()\n",
        "    encoder.fit(all_teams)\n",
        "    mini_ds['HomeId'] = encoder.transform(mini_ds['Home'])\n",
        "    mini_ds['AwayId'] = encoder.transform(mini_ds['Away'])\n",
        "\n",
        "    winner_ids = np.where(mini_ds['FTR'] == 'H', mini_ds['HomeId'], mini_ds['AwayId'])\n",
        "    loser_ids = np.where(mini_ds['FTR'] == 'H', mini_ds['AwayId'], mini_ds['HomeId'])\n",
        "    games = np.column_stack((winner_ids, loser_ids))\n",
        "    names = encoder.classes_\n",
        "\n",
        "    return games, names\n",
        "\n",
        "games, names = load_games()"
      ],
      "metadata": {
        "id": "9y9fzIAk0Mxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLj1WKtJ4OX2"
      },
      "source": [
        "### Q 2.4.a [5 points]\n",
        "\n",
        "Assuming all game outcomes are i.i.d. conditioned on all teams' skills, implement a function $\\texttt{log_games_likelihood}$ that takes a batch of team skills $\\texttt{zs}$ and a collection of observed games $\\texttt{games}$ and gives the total log-likelihoods for all those observations given all the skills.\n",
        "\n",
        "Hint: You should be able to write this function without using $\\texttt{for}$ loops, although you might want to start that way to make sure what you've written is correct.  If $A$ is an array of integers, you can index the corresponding entries of another matrix $B$ for every entry in $A$ by writing $\\texttt{B[A]}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wr-uuBE54Oem"
      },
      "outputs": [],
      "source": [
        "def log_games_likelihood(zs, games):\n",
        "  # games is an array of size (num_games x 2)\n",
        "  # zs is an array of size (num_players)\n",
        "  #\n",
        "  # Hint: With broadcasting, this function can be written\n",
        "  # with no for loops.\n",
        "  #\n",
        "  winning_player_ixs = games[:,0]\n",
        "  losing_player_ixs = games[:,1]\n",
        "  # winning_player_skills =     #TODO: Look up the skill of the winning player in each game.\n",
        "  # losing_player_skills =      #TODO: Look up the skills of the losing player in each game.\n",
        "  # log_likelihoods =           #TODO: Compute the log_likelihood of each game outcome.\n",
        "  # return                      #TODO: Combine the log_likelihood of independent events."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjSQ0_vC4Oll"
      },
      "source": [
        "  \n",
        "### Q 2.4.b [3 points]\n",
        "Implement a function $\\texttt{joint_log_density}$ which combines the log-prior and log-likelihood of the observations to give $p(z_1, z_2, \\dots, z_N, \\text{all game outcomes})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZD2XLUY4O0-"
      },
      "outputs": [],
      "source": [
        "def log_joint_probability(zs, games):\n",
        "  # Todo: Combine log_prior and log_likelihood\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9coJHd8vggOi"
      },
      "source": [
        "### Q 2.4.c [5 points]\n",
        "Run Langevin Monte Carlo on the posterior over all skills conditioned on all the chess games from the dataset.  Run for 10000 samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQUxnXaYgg8J"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "num_players = len(names)\n",
        "n_samples = 10000\n",
        "stepsize = 0.01\n",
        "\n",
        "\n",
        "#Hint: you will need to use games\n",
        "def log_posterior(zs):\n",
        "  pass\n",
        "\n",
        "# TODO: all_games_samples = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GZ1BxGdK_KX"
      },
      "source": [
        "### Q 2.4.d [3 points]\n",
        "Based on your samples from the previous question, plot the approximate mean and variance of the marginal skill of each player, sorted by average skill. There's no need to include the names of the players.  Label the axes \"Player Rank\", and \"Player Skill\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZuGCchtK_Ep"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# mean_skills = ...\n",
        "# var_skills = ...\n",
        "\n",
        "plt.xlabel(\"Player Rank\")\n",
        "plt.ylabel(\"Player Skill\")\n",
        "plt.errorbar(range(num_players), mean_skills, var_skills)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itr6y6kxK--0"
      },
      "source": [
        "### Q 2.4.e [2 points]\n",
        "List the names of the 5 teams with the lowest mean skill and 5 teams with the highest mean skill according to your samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQCFAsJ6K-5A"
      },
      "outputs": [],
      "source": [
        "print(\"Bottom 5\")\n",
        "# TODO: print the 5 players with the lowest mean skill\n",
        "\n",
        "\n",
        "print(\"Top 5\")\n",
        "# TODO: print the 5 players with the highest mean skill\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nN8YuMqK-zB"
      },
      "source": [
        "### Q 2.4.f [2 points]\n",
        "Use a scatterplot to show your samples over the joint posterior over the skills of Southampton and Wolves.  Include the line of equal skill.  Hint: you can use `plt.scatter`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKSLQNCRK-lB"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jloVQ2D_K-Vi"
      },
      "source": [
        "### Q 2.4.g [3 points]\n",
        "Using your samples, find the team that bas the eleventh highest mean skill. Print an unbiased estimate of the probability that the team with the twelfth highest mean skill is not worse than Southampton, again as estimated from your samples. Hint: Probabilities of Bernoulli random variables can be written as the expectation that the Bernoulli takes value 1, so you can use simple Monte Carlo. The final formula will be very simple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-i2YEeYBPkX"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odjXGVCUc8SF"
      },
      "source": [
        "### Q 2.4.h [3 points]\n",
        "\n",
        "For any two players $i$ and $j$, $p(z_i, z_j | \\text{all games})$ is always proportional to $p(z_i, z_j , \\text{all games})$, as a function of $z_i$ and $z_j$.\n",
        "\n",
        "In general, are the isocontours of $p(z_i, z_j | \\text{all games})$ the same as those of $p(z_i, z_j | \\text{games between $i$ and $j$})$?  That is, do the games between other players besides $i$ and $j$ provide information about the skill of players $i$ and $j$?  A simple yes or no suffices.\n",
        "\n",
        "Hint: One way to answer this is to draw the graphical model for three players, $i$, $j$, and $k$, and the results of games between all three pairs, and then examine conditional independencies.  If you do this, include the graphical models in your assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iMV0eKjgf9B"
      },
      "source": [
        "Your answer here:  Yes or no?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "y82CCb3pwLJT"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
